{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ad90fa",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "* Is a collection of samples with features and labels {x,y}\n",
    "* Features: the input data\n",
    "* Labels: The known categories for each sample\n",
    "* Teach the network by showing samples to it\n",
    "* The neural network learns with each feature-label pair\n",
    "\n",
    "\n",
    "# Training process \n",
    "\n",
    "* Training set -> Is used to train the network, itÂ´s the only one that use the training algorythm. We run this algorythm a lot of times\n",
    "\n",
    "* Validation set -> Is used to assess how well our neural network has learned as compared to other competitors. The validation set will allow us to rank our classifiers and choose the one that shows the best performance for us.\n",
    "\n",
    "* Testing set -> Is used for evaluating the finally chosen model, just to make sure it's being able to classify data it hasn't seen before. \n",
    "\n",
    "## One single training sample\n",
    "1 Feed an input sample X to the network\n",
    "2 Compare the output to the correct value Y\n",
    "3 Calculate the error\n",
    "4 Use this error to adjust the weights\n",
    "* The objective: to classify a little better in the future\n",
    "\n",
    "\n",
    "\n",
    "## Training error functions\n",
    "\n",
    "* An error function measures how bad a classifier is doing\n",
    "* This functions is essential in training process\n",
    "\n",
    "### Output error function\n",
    "\n",
    "error = y - out \n",
    "* The output training function must contribute to making out = y, making the error aproach zero\n",
    "\n",
    "\n",
    "### Overall training error function\n",
    "\n",
    "<img src=https://cdn-media-1.freecodecamp.org/images/hmZydSW9YegiMVPWq2JBpOpai3CejzQpGkNG width=200/>\n",
    "\n",
    "* A nice thing about this metric is that it gets rid of the sign of the actual error. So when minimizing the error, we're not interested in the direction of this error. It's all the same to us if the output is over or under the desired value. What we extract from this function is the size of the error. This way we always want to minimize this function\n",
    "\n",
    "### Gradient descent\n",
    "\n",
    "* This is a training method for minimizing the error function\n",
    "* Consists on adjusting the weights to find the minimum error\n",
    "<img src=https://www.mltut.com/wp-content/uploads/2020/04/Untitled-document-3.png width=300/>\n",
    "\n",
    "\n",
    "### The Delta Rule\n",
    "* A simple update formula for adjusting the weights in a neuron\n",
    "\n",
    "<img src=https://miro.medium.com/max/1400/1*ZMJxMF9pJyIz1YBz62cO6g.jpeg width=450/>\n",
    "\n",
    "* it's a unique constant in the neural network. There's only one learning rate for all neurons. As the name suggests, it directly affects the rate of learning because higher values will result in larger leaps for the weights and lower values will result in smaller leaps for the weights.\n",
    "* A higher learning rate mean faster learning but its not better always\n",
    "\n",
    "\n",
    "### Backpropagation algorythm\n",
    "\n",
    "* A general form of the delta rule\n",
    "* Calculates all weight updates throughtout the network\n",
    "* This is done through propagating the error back through the layers\n",
    "\n",
    "Steps:\n",
    "1- Feed a sample to the network\n",
    "2- Calculate the mean squared error\n",
    "3- Calculate the error term of each output neuron\n",
    "\n",
    "    deltaK = Ok*(1 - Ok)*(Yk - Ok)\n",
    "\n",
    "4- Iteratively calculate error terms in the hidden layers\n",
    "<img src=http://www.statistics4u.com/fundstat_eng/img/hl_backprop.png width=400/>\n",
    "\n",
    "5- Apply the delta rule\n",
    "\n",
    "6- Adjust the weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
