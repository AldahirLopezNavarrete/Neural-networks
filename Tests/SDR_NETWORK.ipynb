{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "080fc488",
   "metadata": {},
   "source": [
    "# SDR Neural Network\n",
    "\n",
    "This example of neural network is used to recognize patterns of a simple display, which can represent numbers from 0 to 9.\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/7_segment_display_labeled.svg/1200px-7_segment_display_labeled.svg.png width=200/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b42b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746bc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \"\"\" A single neuron with the sigmoid activate function\n",
    "        Attributtes:\n",
    "            inputs: The number of inputs in the perceptron, not cunting the bias\n",
    "            bias: the bias term. By default itÂ´s 1.0\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, inputs, bias = 1.0):\n",
    "        \"\"\"Return a new Perceptron object with the specified number of inputs +1 (for the bias)\"\"\"\n",
    "        self.weights = np.random.rand(inputs+1)*2 -1\n",
    "        self.bias = bias\n",
    "        \n",
    "    def run(self,x):\n",
    "        \"\"\"Run the perceptron. x is a python list with the input values.\"\"\"\n",
    "        x_sum = np.dot(np.append(x,self.bias),self.weights)\n",
    "        #this calculates the product point of the inputs and the weights\n",
    "        return self.sigmoid(x_sum)\n",
    "    \n",
    "    def set_weights(self,w_init):\n",
    "        \"\"\"Set the weights. w_init is a python list with the weights\"\"\"\n",
    "        self.weights = np.array(w_init)\n",
    "\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        \"\"\"Evaluate the sigmoid function for thw floating point input x\"\"\"\n",
    "        return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7186be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiLayerPerceptron:\n",
    "    \"\"\"A multilayer perceptron class that uses the perceptron class above.\n",
    "        Attributtes:\n",
    "            layers: A python list with the number of elements per layer\n",
    "            bias: The bias term. The same bias is used for all neurons\n",
    "            eta: The learning rate\"\"\"\n",
    "    def __init__(self,layers,bias = 1.0, eta = 0.5):\n",
    "        \"\"\"Return a new MLP object with the specified parameters\"\"\"\n",
    "        self.layers = np.array(layers,dtype=object)\n",
    "        self.bias = bias\n",
    "        self.eta = eta\n",
    "        self.network = [] #the list of all neurons\n",
    "        self.values = [] #the list of all output values\n",
    "        self.d= []\n",
    "        \n",
    "        for i in range(len(self.layers)):\n",
    "            self.values.append([])\n",
    "            self.d.append([])\n",
    "            self.network.append([])\n",
    "            self.values[i] = [0.0 for j in range(self.layers[i])]\n",
    "            self.d[i] = [0.0 for j in range(self.layers[i])]\n",
    "            if i>0:\n",
    "                for j in range(self.layers[i]):\n",
    "                    self.network[i].append(Perceptron(inputs=self.layers[i-1],bias=self.bias))\n",
    "    \n",
    "        self.network = np.array([np.array(x) for x in self.network],dtype=object)\n",
    "        self.values=np.array([np.array(x) for x in self.values],dtype=object)\n",
    "        self.d = np.array([np.array(x) for x in self.d],dtype=object)\n",
    "    \n",
    "    def set_weights(self,w_init):\n",
    "        \"\"\"set the weights.\n",
    "            w_init is a list of lists with the weights for all, but the input layer\"\"\"\n",
    "        for i in range(len(w_init)):\n",
    "            for j in range(len(w_init[i])):\n",
    "                self.network[i+1][j].set_weights(w_init[i][j])\n",
    "                \n",
    "    def printWeights(self):\n",
    "        print()\n",
    "        for i in range(1,len(self.network)):\n",
    "            for j in range(self.layers[i]):\n",
    "                print(\"Layer\",i+1,\"Neuron\",j,self.network[i][j].weights)\n",
    "            print()\n",
    "            \n",
    "    def run(self,x):\n",
    "        \"\"\"Feed a sample x into the multilayer perceptron\"\"\"\n",
    "        x=np.array(x,dtype=object)\n",
    "        self.values[0]=x\n",
    "        for i in range(1,len(self.network)):\n",
    "            for j in range(self.layers[i]):\n",
    "                self.values[i][j]= self.network[i][j].run(self.values[i-1])\n",
    "        return self.values[-1]\n",
    "        \n",
    "    #Backpropagation method\n",
    "    def bp(self, x, y):\n",
    "        \"\"\"Run a single (x,y) pair with the backpropagation algorythm).\"\"\"\n",
    "        x = np.array(x, dtype=object)\n",
    "        y = np.array(y, dtype=object)\n",
    "\n",
    "        #Step 1:  feed a sample to the network\n",
    "        outputs = self.run(x)\n",
    "\n",
    "        #Step 2: calculate the MSE\n",
    "        error = (y-outputs)\n",
    "        MSE = sum(error ** 2)/ self.layers[-1]\n",
    "\n",
    "        #Step 3: Calculate the output error terms\n",
    "        self.d[-1] = outputs * (1-outputs)*error\n",
    "\n",
    "        #Step 4: Calculate the error term of each unit on each layer\n",
    "        for i in reversed(range(1,len(self.network)-1)):\n",
    "            for h in range(len(self.network[i])):\n",
    "                fwd_error = 0.0\n",
    "                for k in range(self.layers[i+1]):\n",
    "                    fwd_error+= self.network[i+1][k].weights[h] * self.d[i+1][k]\n",
    "                self.d[i][h]=self.values[i][h] * (1-self.values[i][h]) * fwd_error\n",
    "\n",
    "        #step 5 & 6 : calculate the deltas and update the weights\n",
    "        #iterates layers\n",
    "        for i in range(1, len(self.network)):\n",
    "            #iterates neurons\n",
    "            for j in range(self.layers[i]):\n",
    "                #iterates inputs\n",
    "                for k in range(self.layers[i-1]+1):\n",
    "                    if k == self.layers[i-1]:\n",
    "                        delta = self.eta * self.d[i][j] *self.bias\n",
    "                    else:\n",
    "                        delta = self.eta * self.d[i][j] * self.values[i-1][k]\n",
    "                    self.network[i][j].weights[k]+=delta\n",
    "\n",
    "        return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e88795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many epochs?1000\n",
      "Training 7 to 1 network ...\n",
      "Training 7 to 10 network ...\n",
      "Training 7 to 7 network ...\n",
      "Input pattern 'a b c d e f g':1 1 1 1 0 1 1 \n",
      "\n",
      "The number recognized by the 7 to 1 network is:  8\n",
      "The number recognized by the 7 to 10 network is:  [2.83478721e-02 3.52516962e-04 5.11598584e-04 7.86678401e-02\n",
      " 4.52836389e-02 4.39168678e-02 2.82695967e-04 3.23383723e-02\n",
      " 4.19715445e-02 9.20259835e-01]\n",
      "The number recognized by the 7 to 7 network is:  [1, 1, 1, 1, 0, 1, 1] \n",
      "\n",
      "Input pattern 'a b c d e f g':0 1 1 0 0 1 1\n",
      "\n",
      "The number recognized by the 7 to 1 network is:  4\n",
      "The number recognized by the 7 to 10 network is:  [2.54716567e-03 5.76089663e-02 4.68548305e-05 2.78645696e-03\n",
      " 9.37305631e-01 1.47071991e-02 1.26531558e-03 1.95673110e-03\n",
      " 2.90204432e-02 2.53196320e-02]\n",
      "The number recognized by the 7 to 7 network is:  [0, 1, 1, 0, 0, 1, 1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test code\n",
    "epochs = int(input(\"How many epochs?\"))\n",
    "mlp1 = MultiLayerPerceptron(layers=[7,7,1])\n",
    "mlp2 = MultiLayerPerceptron(layers=[7,7,10])\n",
    "mlp3 = MultiLayerPerceptron(layers=[7,7,7])\n",
    "\n",
    "print(\"Training 7 to 1 network ...\")\n",
    "#dataset for the 7 to 1 network\n",
    "for i in range(epochs):\n",
    "    mse=0.0\n",
    "    mse+=mlp1.bp([1,1,1,1,1,1,0],[0.05])\n",
    "    mse+=mlp1.bp([0,1,1,0,0,0,0],[0.15])\n",
    "    mse+=mlp1.bp([1,1,0,1,1,0,1],[0.25])\n",
    "    mse+=mlp1.bp([1,1,1,1,0,0,1],[0.35])\n",
    "    mse+=mlp1.bp([0,1,1,0,0,1,1],[0.45])\n",
    "    mse+=mlp1.bp([1,0,1,1,0,1,1],[0.55])\n",
    "    mse+=mlp1.bp([1,0,1,1,1,1,1],[0.65])\n",
    "    mse+=mlp1.bp([1,1,1,0,0,0,0],[0.75])\n",
    "    mse+=mlp1.bp([1,1,1,1,1,1,1],[0.85])\n",
    "    mse+=mlp1.bp([1,1,1,1,0,1,1],[0.95])\n",
    "    mse = mse/10\n",
    "\n",
    "print(\"Training 7 to 10 network ...\")\n",
    "#Dataset for the 7 to 10 network\n",
    "for i in range(epochs):\n",
    "    mse=0.0\n",
    "    mse+=mlp2.bp([1,1,1,1,1,1,0],[1,0,0,0,0,0,0,0,0,0])\n",
    "    mse+=mlp2.bp([0,1,1,0,0,0,0],[0,1,0,0,0,0,0,0,0,0])\n",
    "    mse+=mlp2.bp([1,1,0,1,1,0,1],[0,0,1,0,0,0,0,0,0,0])\n",
    "    mse+=mlp2.bp([1,1,1,1,0,0,1],[0,0,0,1,0,0,0,0,0,0])\n",
    "    mse+=mlp2.bp([0,1,1,0,0,1,1],[0,0,0,0,1,0,0,0,0,0])\n",
    "    mse+=mlp2.bp([1,0,1,1,0,1,1],[0,0,0,0,0,1,0,0,0,0])\n",
    "    mse+=mlp2.bp([1,0,1,1,1,1,1],[0,0,0,0,0,0,1,0,0,0])\n",
    "    mse+=mlp2.bp([1,1,1,0,0,0,0],[0,0,0,0,0,0,0,1,0,0])\n",
    "    mse+=mlp2.bp([1,1,1,1,1,1,1],[0,0,0,0,0,0,0,0,1,0])\n",
    "    mse+=mlp2.bp([1,1,1,1,0,1,1],[0,0,0,0,0,0,0,0,0,1])\n",
    "    mse = mse/10\n",
    "\n",
    "print(\"Training 7 to 7 network ...\")\n",
    "#Dataset for 7 to 7 network\n",
    "for i in range(epochs):\n",
    "    mse=0.0\n",
    "    mse+=mlp3.bp([1,1,1,1,1,1,0],[1,1,1,1,1,1,0])\n",
    "    mse+=mlp3.bp([0,1,1,0,0,0,0],[0,1,1,0,0,0,0])\n",
    "    mse+=mlp3.bp([1,1,0,1,1,0,1],[1,1,0,1,1,0,1])\n",
    "    mse+=mlp3.bp([1,1,1,1,0,0,1],[1,1,1,1,0,0,1])\n",
    "    mse+=mlp3.bp([0,1,1,0,0,1,1],[0,1,1,0,0,1,1])\n",
    "    mse+=mlp3.bp([1,0,1,1,0,1,1],[1,0,1,1,0,1,1])\n",
    "    mse+=mlp3.bp([1,0,1,1,1,1,1],[1,0,1,1,1,1,1])\n",
    "    mse+=mlp3.bp([1,1,1,0,0,0,0],[1,1,1,0,0,0,0])\n",
    "    mse+=mlp3.bp([1,1,1,1,1,1,1],[1,1,1,1,1,1,1])\n",
    "    mse+=mlp3.bp([1,1,1,1,0,1,1],[1,1,1,1,0,1,1])\n",
    "    mse = mse/10\n",
    "    \n",
    "pattern = [1.2]\n",
    "while(pattern[0]>=0.0):\n",
    "    pattern = list(map(float,input(\"Input pattern 'a b c d e f g':\").strip().split()))\n",
    "    if(pattern[0]<0.0):\n",
    "        break\n",
    "    print()\n",
    "    print(\"The number recognized by the 7 to 1 network is: \", int(mlp1.run(pattern)*10))\n",
    "    print(\"The number recognized by the 7 to 10 network is: \", mlp2.run(pattern))\n",
    "    print(\"The number recognized by the 7 to 7 network is: \", [int(x) for x in (mlp3.run(pattern)+0.5)],\"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
